# Hyperparameter Tuning Records

Here, we document the specific adjustments made to the parameters of the three models during the model selection process.

## GRU Model

| Adjustment   | EPOCHS | EARLY_STOP | LR    | MOMENTUM | N_LAYER | DROPOUT | best_loss           | annualized_sharp |
| ------------ | ------ | ---------- | ----- | -------- | ------- | ------- | ------------------- | ---------------- |
| Initial      | 10     | 20         | 0.005 | 0.9      | 1       | 0.3     | -0.5757244267576449 | 1.208191         |
| LR           | 10     | 20         | 0.01  | 0.9      | 1       | 0.3     | -0.576920467655401  | 1.264227         |
| LR           | 10     | 20         | 0.015 | 0.9      | 1       | 0.3     | -0.5911656239548245 | 1.338948         |
| momentum     | 10     | 20         | 0.015 | 0.8      | 1       | 0.3     | -0.5717725689346725 | 1.240296         |
| mometum      | 10     | 20         | 0.015 | 0.95     | 1       | 0.3     | -0.6280331302534892 | 1.442554         |
| LR           | 10     | 20         | 0.02  | 0.95     | 1       | 0.3     | -0.6312035597055343 | 1.471773         |
| LR           | 10     | 20         | 0.025 | 0.95     | 1       | 0.3     | -0.632068543115983  | 1.476785         |
| LR           | 10     | 20         | 0.03  | 0.95     | 1       | 0.3     | -0.631403167304155  | 1.463281         |
| N_layer      | 10     | 20         | 0.025 | 0.95     | 2       | 0.3     | -0.6288703587409612 | 1.442101         |
| N_layer      | 10     | 20         | 0.025 | 0.95     | 3       | 0.3     | -0.6287495980190264 | 1.492026         |
| dropout      | 10     | 20         | 0.025 | 0.95     | 3       | 0.2     | -0.641213603720472  | 1.480795         |
| dropout      | 10     | 20         | 0.025 | 0.95     | 3       | 0.1     | -0.6255420581311792 | 1.482949         |
| EARLY_STOP   | 10     | 15         | 0.025 | 0.95     | 3       | 0.3     | -0.6287495980190264 | 1.492026         |
| EARLY_STOP   | 10     | 25         | 0.025 | 0.95     | 3       | 0.3     | -0.6287495980190264 | 1.492026         |
| epochs       | 20     | 20         | 0.025 | 0.95     | 3       | 0.3     | -0.6383434089051712 | 1.476737         |
| epochs       | 15     | 20         | 0.025 | 0.95     | 3       | 0.3     | -0.6383434089051712 | 1.476437         |
| Final Result | 10     | 20         | 0.025 | 0.95     | 3       | 0.3     | -0.6287495980190264 | 1.492026         |

## TCN Model

| Adjustment   | EPOCHS | EARLY_STOP | LR    | MOMENTUM | kernel_size | n_dropout | n_timestep | best_loss           | annualized_sharp |
| ------------ | ------ | ---------- | ----- | -------- | ----------- | --------- | ---------- | ------------------- | ---------------- |
| Initial      | 10     | 20         | 0.005 | 0.9      | 4           | 0.1       | 63         | -0.5893545426629684 | 1.303985         |
| LR           | 10     | 20         | 0.01  | 0.9      | 4           | 0.1       | 63         | -0.6110552936993741 | 1.346895         |
| LR           | 10     | 20         | 0.015 | 0.9      | 4           | 0.1       | 63         | -0.6164323580828872 | 1.344433         |
| momentum     | 10     | 20         | 0.01  | 0.8      | 4           | 0.1       | 63         | -0.5915605476176415 | 1.308059         |
| momentum     | 10     | 20         | 0.01  | 0.95     | 4           | 0.1       | 63         | -0.6164628871389337 | 1.346970         |
| kernal_size  | 10     | 20         | 0.01  | 0.95     | 6           | 0.1       | 63         | -0.6124709353253647 | 1.325314         |
| kernal_size  | 10     | 20         | 0.01  | 0.95     | 3           | 0.1       | 63         | -0.6166505024239823 | 1.348544         |
| n_dropout    | 10     | 20         | 0.01  | 0.95     | 3           | 0.2       | 63         | -0.6148417173205196 | 1.354061         |
| n_dropout    | 10     | 20         | 0.01  | 0.95     | 3           | 0.3       | 63         | -0.6172268888032114 | 1.347300         |
| EARLY_STOP   | 10     | 15         | 0.01  | 0.95     | 3           | 0.2       | 63         | -0.6148417173205196 | 1.354061         |
| EARLY_STOP   | 10     | 10         | 0.01  | 0.95     | 3           | 0.2       | 63         | -0.6148417173205196 | 1.354061         |
| EPOCHS       | 15     | 15         | 0.01  | 0.95     | 3           | 0.2       | 63         | -0.6148417173205196 | 1.360667         |
| EPOCHS       | 20     | 15         | 0.01  | 0.95     | 3           | 0.2       | 63         | -0.6148417173205196 | 1.382446         |
| Final Result | 20     | 15         | 0.01  | 0.95     | 3           | 0.2       | 63         | -0.6148417173205196 | 1.382446         |

## Transformer Model

| Adjustment   | EPOCHS | EARLY_STOP | LR    | MOMENTUM | n_timestep | n_layer | n_head | n_dropout | n_output | best_loss           | annualized_sharp |
| ------------ | ------ | ---------- | ----- | -------- | ---------- | ------- | ------ | --------- | -------- | ------------------- | ---------------- |
| Initial      | 10     | 20         | 0.005 | 0.9      | 63         | 6       | 5      | 0.1       | 50       | -0.5894355983347506 | 1.470794         |
| LR           | 10     | 20         | 0.01  | 0.9      | 63         | 6       | 5      | 0.1       | 50       | -0.6013632344233024 | 1.382551         |
| momentum     | 10     | 20         | 0.005 | 0.8      | 63         | 6       | 5      | 0.1       | 50       | -0.5790442196098533 | 1.460378         |
| momentum     | 10     | 20         | 0.005 | 0.95     | 63         | 6       | 5      | 0.1       | 50       | -0.5867310061648086 | 1.416763         |
| LR           | 10     | 20         | 0.003 | 0.9      | 63         | 6       | 5      | 0.1       | 50       | -0.5711446718589679 | 1.456280         |
| n_layer      | 10     | 20         | 0.005 | 0.9      | 63         | 7       | 5      | 0.1       | 50       | -0.5864171993893545 | 1.445975         |
| n_layer      | 10     | 20         | 0.005 | 0.9      | 63         | 5       | 5      | 0.1       | 50       | -0.5826917218195425 | 1.381299         |
| n_dropout    | 10     | 20         | 0.005 | 0.9      | 63         | 6       | 5      | 0.2       | 50       | -0.5864803420530784 | 1.421642         |
| n_dropout    | 10     | 20         | 0.005 | 0.9      | 63         | 6       | 5      | 0.3       | 50       | -0.5896841529253368 | 1.467239         |
| n_dropout    | 10     | 20         | 0.005 | 0.9      | 63         | 6       | 5      | 0.35      | 50       | -0.5876819547769186 | 1.456735         |
| EARLY_STOP   | 10     | 15         | 0.005 | 0.9      | 63         | 6       | 5      | 0.1       | 50       | -0.5894355983347506 | 1.470794         |
| EARLY_STOP   | 10     | 25         | 0.005 | 0.9      | 63         | 6       | 5      | 0.1       | 50       | -0.5894355983347506 | 1.470794         |
| epochs       | 20     | 20         | 0.005 | 0.9      | 63         | 6       | 5      | 0.1       | 50       | -0.5894355983347506 | 1.337258         |
| epochs       | 15     | 20         | 0.005 | 0.9      | 63         | 6       | 5      | 0.1       | 50       | -0.5894355983347506 | 1.398831         |
| Final Result | 10     | 25         | 0.005 | 0.9      | 63         | 6       | 5      | 0.1       | 50       | -0.5894355983347506 | 1.470794         |

### Summary

â€‹	It can be seen that the GRU model has the best performance under the final hyperparameters. The extreme value of the loss during training and the Sharpe ratio on the validation set are both superior to the other two models. Therefore, we ultimately chose the GRU model for the comparative experiment.