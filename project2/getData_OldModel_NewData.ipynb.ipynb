{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a30860-9452-4ee3-bf46-ef40b997e585",
   "metadata": {},
   "source": [
    "# 读取数据并进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2166d237-b36a-4ebf-b7a8-f1f1814d3a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available.\n",
      "Number of available GPUs: 1\n",
      "Current GPU device: 0\n",
      "GPU device name: NVIDIA GeForce RTX 4090 D\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "gpu_available = torch.cuda.is_available()\n",
    "\n",
    "if gpu_available:\n",
    "    print(\"GPU is available.\")\n",
    "    print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current GPU device: {torch.cuda.current_device()}\")\n",
    "    print(f\"GPU device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5f3bde-7a09-4d50-9df7-ad69d2f94eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from operator import add\n",
    "from functools import reduce\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aad433e-4f80-4c25-b37a-d7628ee970b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指数的值\n",
    "data = pd.read_csv('../DL_new/DL_Markowitz/data/return_df.csv')\n",
    "# 使用上一行的值填充缺失值\n",
    "df_filled = data.ffill()\n",
    "# 使用下一行的值填充仍然存在的缺失值\n",
    "data = df_filled.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a85bf6d-671a-4b6e-8852-90f8e51562d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['AAPL', 'ABT', 'ACN', 'ADBE', 'AMZN', 'BAC', 'BMY', 'BRK-B', 'C', 'CMCSA', 'COST', 'CSCO', 'CVX', 'DHR', 'DIS', 'GS', 'HD', 'HON', 'INTC', 'INTU', 'JNJ', 'JPM', 'KO', 'LIN', 'LLY', 'MCD', 'MDT', 'MRK', 'MS', 'MSFT', 'NEE', 'NFLX', 'NKE', 'NVDA', 'ORCL', 'PEP', 'PFE', 'PG', 'QCOM', 'SBUX', 'T', 'TMO', 'TXN', 'UNH', 'UNP', 'UPS', 'VZ', 'WFC', 'WMT', 'XOM'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_csv_files_to_dict(directory_path):\n",
    "    csv_files = [f for f in os.listdir(directory_path) if f.endswith('.csv')]\n",
    "    dataframes = {}\n",
    "\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        # 使用上一行的值填充缺失值\n",
    "        df_filled = df.ffill()\n",
    "        # 使用下一行的值填充仍然存在的缺失值\n",
    "        df = df_filled.bfill()\n",
    "        file_name_without_extension = os.path.splitext(file)[0]\n",
    "        dataframes[file_name_without_extension] = df\n",
    "    return dataframes\n",
    "\n",
    "# 使用示例\n",
    "directory_path = '../DL_new/DL_Markowitz/data/stocks/'\n",
    "# 替换成实际的文件夹路径\n",
    "csv_dataframes = read_csv_files_to_dict(directory_path)\n",
    "\n",
    "# 打印字典中的keys作为验证\n",
    "print(csv_dataframes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6af50bb0-6a35-4776-a537-30c1502f02ad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_missing_values(stock_dict):\n",
    "    for stock, df in stock_dict.items():\n",
    "        if df.isnull().values.any():\n",
    "            raise ValueError(f\"DataFrame for stock {stock} contains missing values\")\n",
    "            \n",
    "check_missing_values(csv_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e0d95a2-1db4-4a86-9758-88fb4c4b8303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_dates(stock_dict):\n",
    "    # 获取所有的股票代码\n",
    "    all_stocks = list(stock_dict.keys())\n",
    "    \n",
    "    # 提取每个DataFrame的日期，并求交集\n",
    "    common_dates = set(stock_dict[all_stocks[0]]['Date'])\n",
    "    for stock in all_stocks[1:]:\n",
    "        common_dates &= set(stock_dict[stock]['Date'])\n",
    "    \n",
    "    common_dates = sorted(list(common_dates))\n",
    "    \n",
    "    # 只保留共同存在的日期\n",
    "    for stock in all_stocks:\n",
    "        stock_dict[stock] = stock_dict[stock][stock_dict[stock]['Date'].isin(common_dates)].reset_index(drop=True)\n",
    "    \n",
    "    return stock_dict, common_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea0ffefd-05ed-42fa-b046-dff642798710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5093\n"
     ]
    }
   ],
   "source": [
    "csv_dataframes, dates = align_dates(csv_dataframes)\n",
    "print(len(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "294468b7-313d-47d5-bcbf-ce8e2868f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_4d_tensorX(stock_dict, n_days):\n",
    "    all_stocks = list(stock_dict.keys())\n",
    "    all_dates = sorted(stock_dict[all_stocks[0]]['Date'])\n",
    "    print(len(all_dates))\n",
    "    date_to_index = {date: idx for idx, date in enumerate(all_dates)}\n",
    "\n",
    "    num_dates = len(all_dates)\n",
    "    num_stocks = len(all_stocks)\n",
    "    num_features = len(stock_dict[all_stocks[0]].columns) - 1\n",
    "\n",
    "    tensor = np.zeros((num_dates, n_days, num_stocks, num_features))\n",
    "\n",
    "    for stock_idx, stock in tqdm(enumerate(all_stocks), total=len(all_stocks), desc=\"Processing stocks\"):\n",
    "        df = stock_dict[stock]\n",
    "        df.set_index('Date', inplace=True)\n",
    "        df = df.sort_index()\n",
    "        for date_idx, current_date in enumerate(all_dates):\n",
    "            start_date_idx = max(0, date_idx - n_days + 1)\n",
    "            relevant_dates = all_dates[start_date_idx:date_idx + 1]\n",
    "            for n_day_idx, past_date in enumerate(relevant_dates):\n",
    "                past_date_idx = date_to_index[past_date]\n",
    "                tensor[date_idx, n_day_idx, stock_idx, :] = df.loc[past_date].values\n",
    "\n",
    "    tensor = torch.tensor(tensor, dtype=torch.float32)\n",
    "    return tensor\n",
    "\n",
    "def add_batch_dimensionX(tensor, batch_size):\n",
    "    # 获取当前张量的第一个维度的长度\n",
    "    num_dates = tensor.shape[0]\n",
    "\n",
    "    # 计算有多少个完整的批次\n",
    "    num_batches = (num_dates + batch_size - 1) // batch_size\n",
    "\n",
    "    # 初始化带有批次的新张量\n",
    "    new_shape = (num_batches, batch_size) + tensor.shape[1:]\n",
    "    batched_tensor = torch.zeros(new_shape, dtype=tensor.dtype)\n",
    "\n",
    "    # 填充新的带有批次的张量\n",
    "    for i in tqdm(range(num_batches), desc=\"Adding batch dimension\"):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min(start_idx + batch_size, num_dates)\n",
    "        batched_tensor[i, :end_idx-start_idx] = tensor[start_idx:end_idx]\n",
    "\n",
    "    return batched_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c57a44f3-52f3-4c0d-9f49-fd91f5eea87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_4d_tensorY(stock_dict, n_days, b):\n",
    "    all_stocks = list(stock_dict.keys())\n",
    "    all_dates = sorted(stock_dict[all_stocks[0]]['Date'])\n",
    "    print(len(all_dates))\n",
    "    date_to_index = {date: idx for idx, date in enumerate(all_dates)}\n",
    "\n",
    "    num_dates = len(all_dates)\n",
    "    num_stocks = len(all_stocks)\n",
    "\n",
    "    tensor = np.zeros((num_dates, 1, num_stocks, b))\n",
    "\n",
    "    def fill_nan_with_nearest(array):\n",
    "        \"\"\"填充NaN值，用临近的值进行填充\"\"\"\n",
    "        nan_indices = np.isnan(array)\n",
    "        if np.any(nan_indices):\n",
    "            # 获取非NaN值的索引和值\n",
    "            not_nan_indices = np.where(~nan_indices)[0]\n",
    "            not_nan_values = array[not_nan_indices]\n",
    "            # 使用最近的非NaN值进行填充\n",
    "            nearest_values = np.interp(np.where(nan_indices)[0], not_nan_indices, not_nan_values)\n",
    "            array[nan_indices] = nearest_values\n",
    "        return array\n",
    "\n",
    "    for stock_idx, stock in tqdm(enumerate(all_stocks), total=len(all_stocks), desc=\"Processing stocks\"):\n",
    "        df = stock_dict[stock]\n",
    "        df.set_index('Date', inplace=True)\n",
    "        df = df.sort_index()\n",
    "        df['Avg'] = (df['Open'] + df['Close']) / 2\n",
    "        df['Future_Return'] = (df['Avg'].shift(-n_days) - df['Avg']) / df['Avg']\n",
    "        \n",
    "        # 检查并填充NaN值\n",
    "        df['Future_Return'] = fill_nan_with_nearest(df['Future_Return'].values)\n",
    "\n",
    "        for date_idx, current_date in enumerate(all_dates):\n",
    "            target_idx = date_idx + n_days\n",
    "            if target_idx < len(df):\n",
    "                future_return = df['Future_Return'].iloc[target_idx]\n",
    "            else:\n",
    "                future_return = df['Future_Return'].iloc[-1]\n",
    "            tensor[date_idx, 0, stock_idx, :] = future_return\n",
    "\n",
    "    tensor = torch.tensor(tensor, dtype=torch.float32)\n",
    "    return tensor\n",
    "\n",
    "def add_batch_dimensionY(tensor, batch_size):\n",
    "    # 获取当前张量的第一个维度的长度\n",
    "    num_dates = tensor.shape[0]\n",
    "\n",
    "    # 计算有多少个完整的批次\n",
    "    num_batches = (num_dates + batch_size - 1) // batch_size\n",
    "\n",
    "    # 初始化带有批次的新张量\n",
    "    new_shape = (num_batches, batch_size) + tensor.shape[1:]\n",
    "    batched_tensor = torch.zeros(new_shape, dtype=tensor.dtype)\n",
    "\n",
    "    # 填充新的带有批次的张量\n",
    "    for I in tqdm(range(num_batches), desc=\"Adding batch dimension\"):\n",
    "        start_idx = I * batch_size\n",
    "        end_idx = min(start_idx + batch_size, num_dates)\n",
    "        batched_tensor[I, :end_idx-start_idx] = tensor[start_idx:end_idx]\n",
    "\n",
    "    return batched_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "920dc447-c46a-4f98-9db8-6b415da3a300",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stocks: 100%|██████████| 50/50 [08:54<00:00, 10.69s/it]\n",
      "Adding batch dimension: 100%|██████████| 2547/2547 [00:00<00:00, 63678.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stocks: 100%|██████████| 50/50 [00:03<00:00, 15.12it/s]\n",
      "Adding batch dimension: 100%|██████████| 2547/2547 [00:00<00:00, 231111.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# 调整成四维张量\n",
    "past_days = 63\n",
    "future_days = 21\n",
    "factors = 2\n",
    "batch_size = 2\n",
    "# 生成X的\n",
    "tensorX = create_4d_tensorX(csv_dataframes, past_days)\n",
    "dataX = add_batch_dimensionX(tensorX, batch_size)\n",
    "# 重新读取数据\n",
    "csv_dataframes = read_csv_files_to_dict(directory_path)\n",
    "csv_dataframes, dates = align_dates(csv_dataframes)\n",
    "# 生成Y的\n",
    "tensorY = create_4d_tensorY(csv_dataframes, future_days, factors)\n",
    "dataY = add_batch_dimensionY(tensorY, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d99e12a-075a-4bac-8008-8b6791a177f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./new_data.pkl', 'wb') as f:\n",
    "    pickle.dump((dataX, dataY), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1248bb4-4b63-4c4c-8343-57ebf86f687d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2547, 2, 63, 50, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dbb788f-d779-483d-a1e1-0379eeb20b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2547, 2, 1, 50, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataY.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5179c7-b30a-48af-8360-77f180bfdb45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6588e30d-7968-4849-8771-90956db0d74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-05-23</th>\n",
       "      <td>0.436607</td>\n",
       "      <td>0.450714</td>\n",
       "      <td>0.429821</td>\n",
       "      <td>0.449643</td>\n",
       "      <td>0.381153</td>\n",
       "      <td>369398400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-24</th>\n",
       "      <td>0.446250</td>\n",
       "      <td>0.446250</td>\n",
       "      <td>0.427857</td>\n",
       "      <td>0.431250</td>\n",
       "      <td>0.365562</td>\n",
       "      <td>166174400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-27</th>\n",
       "      <td>0.446250</td>\n",
       "      <td>0.446250</td>\n",
       "      <td>0.427857</td>\n",
       "      <td>0.431250</td>\n",
       "      <td>0.364275</td>\n",
       "      <td>166174400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-28</th>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.432143</td>\n",
       "      <td>0.418393</td>\n",
       "      <td>0.428214</td>\n",
       "      <td>0.362988</td>\n",
       "      <td>149716000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-29</th>\n",
       "      <td>0.427143</td>\n",
       "      <td>0.436429</td>\n",
       "      <td>0.418750</td>\n",
       "      <td>0.428214</td>\n",
       "      <td>0.362988</td>\n",
       "      <td>221793600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-23</th>\n",
       "      <td>161.119995</td>\n",
       "      <td>161.800003</td>\n",
       "      <td>159.059998</td>\n",
       "      <td>161.410004</td>\n",
       "      <td>159.586609</td>\n",
       "      <td>96041900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-24</th>\n",
       "      <td>160.750000</td>\n",
       "      <td>162.139999</td>\n",
       "      <td>159.639999</td>\n",
       "      <td>161.940002</td>\n",
       "      <td>160.110626</td>\n",
       "      <td>69463600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-25</th>\n",
       "      <td>160.750000</td>\n",
       "      <td>162.139999</td>\n",
       "      <td>159.639999</td>\n",
       "      <td>161.940002</td>\n",
       "      <td>157.574593</td>\n",
       "      <td>69463600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-26</th>\n",
       "      <td>159.570007</td>\n",
       "      <td>160.449997</td>\n",
       "      <td>156.360001</td>\n",
       "      <td>156.809998</td>\n",
       "      <td>155.038559</td>\n",
       "      <td>76959800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-29</th>\n",
       "      <td>159.369995</td>\n",
       "      <td>161.190002</td>\n",
       "      <td>158.789993</td>\n",
       "      <td>160.240005</td>\n",
       "      <td>158.429825</td>\n",
       "      <td>88748200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5093 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2002-05-23    0.436607    0.450714    0.429821    0.449643    0.381153   \n",
       "2002-05-24    0.446250    0.446250    0.427857    0.431250    0.365562   \n",
       "2002-05-27    0.446250    0.446250    0.427857    0.431250    0.364275   \n",
       "2002-05-28    0.423036    0.432143    0.418393    0.428214    0.362988   \n",
       "2002-05-29    0.427143    0.436429    0.418750    0.428214    0.362988   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2021-11-23  161.119995  161.800003  159.059998  161.410004  159.586609   \n",
       "2021-11-24  160.750000  162.139999  159.639999  161.940002  160.110626   \n",
       "2021-11-25  160.750000  162.139999  159.639999  161.940002  157.574593   \n",
       "2021-11-26  159.570007  160.449997  156.360001  156.809998  155.038559   \n",
       "2021-11-29  159.369995  161.190002  158.789993  160.240005  158.429825   \n",
       "\n",
       "                 Volume  \n",
       "Date                     \n",
       "2002-05-23  369398400.0  \n",
       "2002-05-24  166174400.0  \n",
       "2002-05-27  166174400.0  \n",
       "2002-05-28  149716000.0  \n",
       "2002-05-29  221793600.0  \n",
       "...                 ...  \n",
       "2021-11-23   96041900.0  \n",
       "2021-11-24   69463600.0  \n",
       "2021-11-25   69463600.0  \n",
       "2021-11-26   76959800.0  \n",
       "2021-11-29   88748200.0  \n",
       "\n",
       "[5093 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataframes['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2adc75-102c-4afd-a074-20bbdfb60b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d1182-b88e-4fad-8704-3dc4d8e10ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
